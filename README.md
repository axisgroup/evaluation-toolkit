# Evaluation Toolkit
This repo is a collection of resources intended to help guide and improve the evaluation process of data visualizations. It is written by and for the Axis Design team, but can also act as a point of reference for all data vis practitioners.

The goal of this repo is to serve as a **toolkit** that helps deconstruct the testing process into manageable chunks.
It aims to:
* Identify pitfalls in our current evaluation process
* Provide direction for self-guided evaluation by means of best practices
* Equip designers with the tools necessary for testing visualizations

Designers should be able to use this repo to determine success criteria for their projects, prioritize which attributes to test, and conduct more focused and productive user tests.

This is a **WIP** living document. Please read our [Contribution Guidelines](CONTRIBUTING.md) to help refine this repo.


## How to Use this Toolkit 

The approach advocated by this repo is:
 ```
  1. Follow best practices
  2. Determine research questions
  3. Plan the test
  4. Conduct the test
  5. Act on your findings
 ```  
To break down the contents of each phase:

0. [**Setting the Stage**](/0.Setting-the-Stage/)

   Before beginning the evaluation process, its's helpful to first: 
   * Understand the inherent [complexity](./0.Setting-the-Stage/Challenges.md) that comes with evaluating a data visualization,
   * Understand the [pitfalls](./0.Setting-the-Stage/Pitfalls.md) with the current evaluation methodologies, in order to prevent yourself from falling into them, and
   * Equip yourself with the [testing mindset](./0.Setting-the-Stage/TestingMindset.md) in order to properly set expectations.

1. [**Follow Best Practices**](/1.Follow-best-practices)

   At a strategic level, this serves as an initial self-directed reflection, intended to help you determine the most important design criteria for the success of your project, as well as to help you improve the current design based on known best practices. At a tactical level, it provides guidelines to help you evaluate specific UI elements such as typography, color, and arrangement (see [Data Visualization Checklist](/1.Follow-best-practices/DataVizChecklist-May2016.pdf) prepared by Stephanie Evergreen and Ann K. Emery).

2. [**Determine Research Questions**](/2.Determine-research-questions)

   Next, you will need to determine what it is you specifically want to test and measure, and what attributes you want to prioritize for your dashboard. Do you want to test its usability, usefulness, desirability, or a combination of these attributes? This section provides
   * A list of desirable attributes and the corresponding questions you can ask to test those attributes
   * A list of unwanted attributes you can use to cross your visualization against
   * Guidelines on determining the style of data you should capture (verbal, multiple choice, rating, written, etc.)
   * The [Axis Design Sprint Testing Template](https://docs.google.com/spreadsheets/d/1lfcPwG4gH-rQQhl5MuXgNevy8_hlJPvdx6_RiLT34qw/edit?usp=sharing) that can be used to begin documenting the evaluation process

3. [**Plan the Test**](/3.Plan-the-test)

   Now that you have pinpointed the relevant questions and attributes, you can use this page to devise a testing plan and methodology. This page includes information on:
   * Recruiting users/evaluators for your test
   * Choosing the right test (Attitudinal or behavioral? Qualitative or quantitative? What's the context of use?)
   * Choosing the right tasks 
   
4. [**Conduct the Test**](/4.Conduct-the-test)

   After you've mapped out the type of test that would be most appropriate for colelcting feedback, you can reference this page to see specific research methods and instructions on how to conduct them.
   * [Usability testing to gauge the overall User Experience](./Research-Methods/UsabilityTesting/README.md)
   * [Expert Reviews/Heuristic Evaluation](./Research-Methods/ExpertReview/README.md)
   * [System Usability Scale](./Research-Methods/SUS/README.md)
   
5. [**Act on your Findings**](/5.Act-on-your-findings)

   Now comes the redesign and iteration. After conducting your tests, you'll need to analyze your results, then translate them into action items. This section provides resources on 
   * Resources on analyzing both quantitative and qualitative data 
   * A [Checklist of potential actions](./5.Act-on-your-findings/Checklist-of-potential-actions.md) for design and usability changes you can make based on feedback
   * Guidelines to conveying your findings

## Putting it all together

### Axis Design Sprint Testing Template

Throughout the sprint we want to track how research questions mature as the design sprint progresses and what methods were used to answer those questions. Copy over this [Google Sheets document](https://docs.google.com/spreadsheets/d/1lfcPwG4gH-rQQhl5MuXgNevy8_hlJPvdx6_RiLT34qw/edit#gid=0) to your own drive to help guide and document your testing process.

Acknowledgements: Thanks to [Arielle Cason, UX Researcher](http://ariellecason.com/) for sharing her personal test templat (developed while she was a graduate student at Georgia Institute of Technology) with us. We were able to use her template as a substrate to build our own.

Here is a snippet of her template-

![Testing Template](./Assets/images/Sample-Testing-Template.png)

****
**[License](LICENSE.md)**

Copyright Â© 2017 Axis Group, LLC. The information contained in this document is free, and may be redistributed under the terms specified in the license.

