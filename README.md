## Know your guidelines before you break them

The goal of this repository is to serve as a **toolkit** that helps deconstruct the testing process into manageable chunks.
This toolkit aims to:
- To help identify [pitfalls](Pitfalls.md) in our current evaluation process, so designers can be more cognizant of them and control for them when possible.
- To provide enough guidelines to designers to reduce the cognitive load of decision making at every stage.


Specifically, the approach advocated by this repository is three-pronged:

       	1. Follow best practices, don't re-invent the wheel
        	2. Know what to measure?
         	3. Know how to measure?
With these guidelines designers can determine success criteria for their project, prioritize what to test versus what not to test, and identify shortcut methods to test for them. 

Where possible, this toolkit will also attempt to identify tactics designers can employ to improve their evaluation process. This repositiory is meant to act as a point of reference for data vis practitioners rather than an educational resource.

This is a **WIP** living document. Please read our [Contribution Guidelines](CONTRIBUTING.md) to help refine this repository.

## How to use this toolkit

1. **Follow best practices:** This serves as an initial self-directed evaluation, intended to help you determine whether your visualization is following best practices, particularly in regard to styling. Reference the [data visualization checklist](DataVizChecklist_May2016.pdf) to evaluate specific UI elements such as typography, color, and arrangement.

2. **Know what to measure:** Next, you can begin the process of user testing by first determining what you speficially want to test and measure, and what attributes you want to prioritize for your dashboard. Do you want to test its usability, usefulness, desirability, or a combination of these attributes? Reference the [Desirable Attributes](evaluation-toolkit/2. Determining what to measure/Desirable Attributes.md) for a list of questions that can be asked to help you determine whether your visualization achieves your prioritized attributes.

3. **Know how to measure:** Now that you have pinpointed the relevant questions and attributes, you can use reference this page to devise a testing plan and methodology.
